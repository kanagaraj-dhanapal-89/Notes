current usage:
    Tools Used:
        -- Spark
        -- Kafka
        -- Docker
        -- Kubernetes
        -- ArgoCD
        -- Grafana
        -- Hudi
        -- Helm Chat

    Flows:
        --K2H
        --K2GCS
        --GCS2GCS


1) what is kubernetes?
    Kubernetes is an open-source container orchestration tool or system that is used to automate tasks such as the management, monitoring, scaling, and deployment of containerized applications.

2) What are the main components of Kubernetes architecture?
    -- master node
    -- worker node

3) Kubernetes architecture:
    -- cluster store (KV)
        -- stores configuration details and essentail values
        -- it communicates with all other components to receive the commands to perform the actions
        -- manages network rules and post forwarding activity
    -- controller
        -- replication controllers
        -- endpoint controllers
        -- namespace controller
        -- service account controller
    -- scheduler
        -- Assign the task to the slave nodes
        -- Distributing the workload and stores the resource usage information

    -- Api-server
        -- API server to perform all operations on the cluster

4) kubelet
    -- responsible for maintaining the work status and the node server

5) Kubernetes Proxy
    -- load balancer
    -- network proxy to perform service on a single worker node
    -- Manages pods on nodes, volumes, secrets, the creation of new containers, health check-ups

6) Hereâ€™s a review of the fundamental concepts of Kubernetes architecture.

    Pod: A group of containers
    Labels: Used to identify pods
    Kubelet: Container agents responsible for maintaining pod sets
    Proxy: Pod load balancers that help distribute tasks
    Etcd: A metadata service
    CAdvisor: Monitors resource performance and usage
    Replication controller: Manages pod replication
    Scheduler: Schedules pods in worker nodes

7) Heapster
    -- performance monitor
    -- metrics collection system for data collected by kublet

8) Namespace in Kubernetes:
    -- dividing cluster resources between multiple users.

9) initial namespaces
    -- default
    -- kube - system
    -- kube - public

10) Ingress network
    -- all users to access the kubernetes services from outside

11) headless service
    -- tied to a ClusterIP
    -- allowing you to directly reach pods without having to access them through a proxy.
    -- it is useful when neither load balancing nor a single Service IP is required.

12) federated clusters:
    -- multiple clusters that treat them as a single logical cluster

13) Daemon sets
    --  a set of pods that runs only once on a host

---------------------------------------------------------------------------------------------------------------

Basic Concepts:

What is Docker?
What are the benefits of using Docker containers?
What is the difference between a Docker image and a Docker container?
    Docker:
        An image is a read-only template with instructions for creating a Docker container.
        Often, an image is based on another image, with some additional customization

     Docker containers:
        A container is a runnable instance of an image.
        You can create, start, stop, move, or delete a container using the Docker API or CLIA container is a runnable instance of an image.

How does Docker work? (Explain the concept of containerization and the Docker daemon)

Containerization:
    Traditional Virtualization: Imagine virtual machines (VMs) as separate computers running within your physical computer. Each VM has its own operating system, applications, libraries, and files. This creates a heavy resource footprint and makes deployments complex.
    Containerization: Docker uses containerization, a lighter-weight alternative. Containers share the host operating system's kernel but run in isolated user space. They have their own file systems and applications, but leverage the host's resources more efficiently. This makes them faster to start, stop, and deploy than VMs.

The Docker Daemon:
    Central Hub: At the core of Docker is the Docker daemon, a background process that manages the building, running, and distribution of Docker containers.
    Building Images: You define the container's configuration in a text file called a Dockerfile. The Dockerfile specifies instructions like the base operating system, packages to install, and the application to run. The Docker daemon reads the Dockerfile and builds a Docker image, which is a self-contained archive containing the application and all its dependencies.
    Running Containers: You can use the Docker daemon to run containers from existing images. The daemon creates an isolated instance of the container based on the image, allocating resources and starting the application.
    Image Registry: Docker Hub is a public registry where users can share and discover Docker images. You can pull pre-built images from Docker Hub or push your own images for sharing.


What is a Dockerfile? Explain the different instructions used in a Dockerfile.
     The Dockerfile specifies instructions like the base operating system, packages to install, and the application to run

What is a Docker registry? (e.g., Docker Hub)
    Docker Hub is a public registry where users can share and discover Docker images. You can pull pre-built images from Docker Hub or push your own images for sharing.

How do you manage volumes in Docker containers?

    Understanding Volumes:

        Volumes are directories that persist data outside the container's ephemeral file system. This means data written to a volume persists even if the container is stopped, restarted, or deleted.
        This is crucial for storing application data (databases, configurations, uploads) that needs to survive container lifecycle events.

    Mounting Volumes:

    You use the -v or --volume flag in the docker run command to mount a volume into a container.
    The syntax is: docker run -v <host_directory>:<container_directory> <image_name>
    <host_directory>: The directory on the Docker host machine where you want to persist data.
    <container_directory>: The directory inside the container where you want to mount the volume. This is where the application will access its data.
    Types of Volumes:

    Local Volumes: The most basic type, where the host directory is a physical directory on your machine.
    Named Volumes: Volumes managed by Docker and referenced by name across multiple containers. Useful for sharing data between containers.
    Bind Mounts: Similar to local volumes, but bind mounts use existing directories on the host. Be cautious with these as changes inside the container affect the host directory as well.
    Docker Volumes Plugin: Docker supports plugins for external volume providers like cloud storage solutions (e.g., AWS EBS, Azure Disks). This allows persistent data storage on remote locations.

    Benefits of Volumes:

    Data Persistence: Ensures your application data survives container restarts or upgrades.
    Data Sharing: Allows multiple containers to access the same persistent data volume.
    Configurability: Separates application data from the container image, making deployments easier.



How do you link Docker containers?
    Legacy Linking:
    Concept: Linking allows you to establish a connection between two running containers. You specify a source container and an alias for it within the target container. The target container can then access the source container using the alias and its exposed ports.
    Syntax: The --link flag in the docker run command is used for linking:
    Bash:
        docker run --link <source_container_name>:<alias> <target_image_name>

How do you expose ports in a Docker container?

    Understanding Port Exposure:

    Containers run in isolated user space and don't directly expose ports to the host system.
    To allow external applications or services to communicate with your containerized application, you need to map container ports to host ports.
    Exposing Ports with docker run:

    You use the -p or --publish flag in the docker run command to expose a container port.
    The syntax is: docker run -p <host_port>:<container_port> <image_name>
    <host_port>: The port number you want to use on the Docker host machine to access the container. Choose a port that isn't already in use.
    <container_port>: The port number that your application listens on inside the container.
    Example:

    Bash
    docker run -p 8080:8080 my_web_app_image

What is the difference between Docker Swarm and Kubernetes?
Feature	    Docker Swarm	                    Kubernetes
Deployment	Built-in with Docker, simpler setup	Dedicated orchestration tool, complex setup
Management	Service discovery, load balancing	Robust features (scaling, health checks, self-healing)
Scalability	Smaller deployments	Highly scalable for large environments
Features	Limited advanced features	Wide range of features for application lifecycle management
Networking	Overlay networks, limited control	Granular control, network plugins
Security	User access control	RBAC, pod security policies

Advanced Concepts:

How do you build a multi-stage Docker build?
Explain Docker networking modes (bridge, host, overlay, etc.)
How do you handle environment variables in Docker containers?
What are Docker secrets and configs?
How do you secure Docker containers?
How do you monitor Docker containers?
What are Docker Compose and its benefits?
Explain Docker content trust and how it ensures image authenticity.
Kubernetes Interview Questions:

Basic Concepts:
What is Kubernetes?
What are the core components of Kubernetes (e.g., pods, deployments, services, etc.)?
How does Kubernetes work? (Explain the role of the control plane and worker nodes)
What are the benefits of using Kubernetes?
What is a Kubernetes pod? Explain the difference between a ReplicaSet and a Deployment.
What is a Kubernetes service? Explain the different types of services (e.g., NodePort, LoadBalancer)
How do you scale deployments in Kubernetes?
How do you manage secrets and configuration data in Kubernetes?
How do you expose a Kubernetes service externally?

Advanced Concepts:
How do you handle rolling updates and rollbacks in Kubernetes?
What are Kubernetes namespaces and their purpose?
Explain Ingress resources and how they route traffic to services.
How do you monitor and troubleshoot applications running in Kubernetes?
What are Kubernetes Persistent Volumes (PVs) and Persistent Volume Claims (PVCs)?
What are custom resources and operators in Kubernetes?
How do you achieve high availability in Kubernetes deployments?
Explain different scheduling strategies in Kubernetes.
What are security best practices for deploying applications in Kubernetes?
Bonus:

Be prepared to discuss your experience with container orchestration tools or platforms besides Docker and Kubernetes (e.g., Docker Swarm, Rancher)
Be able to explain real-world use cases of Docker and Kubernetes in different industries.
These are some of the common Docker and Kubernetes interview questions. The specific questions you encounter will depend on the role you are applying for and the company's specific needs. It's always a good idea to research the company and the specific role beforehand to tailor your answers accordingly.

Here are some additional resources that you may find helpful:

Docker Documentation: https://docs.docker.com/
Kubernetes Documentation: https://kubernetes.io/docs/home/
Practice Kubernetes with Katacoda: https://kubernetes.io/blog/2023/02/14/kubernetes-katacoda-tutorials-stop-from-2023-03-31/

